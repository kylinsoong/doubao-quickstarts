= 大模型行业趋势
:toc: manual

== 大模型飞跃发展

过去这一年，我们见证了大模型技术前所未有的飞跃。去年 12 月，豆包大模型的日均 Token 调用量已经达到了 4 万亿次。而截止到今年 3 月底，这个数字已经突破了 12.7 万亿。根据我们内部统计数据，在不到一年的时间里，我们实现了超过 106 倍的高速增长。

这样的增长不仅仅体现了豆包大模型本身的迅猛发展，更是整个大模型行业飞速前进的一个缩影。如今，大模型正快速走入我们的工作与生活，越来越多的企业也正在将豆包大模型作为自身 AI 转型的关键选择。

我们来看一些实际案例：

* 在办公领域，金山办公基于豆包大模型，打造了全新的 AI 智能助手“明晰”，大幅提升了文档处理、创意写作、信息检索等方面的效率。
* 在汽车行业，梅赛德斯奔驰选择豆包大模型作为智能座舱的核心，通过豆包大模型，奔驰实现了信息检索能力的升级，系统反应更快，研发效率也显著提升。而不仅仅是奔驰，如今接近 八成的主流汽车品牌，都已将豆包大模型作为其 AI 升级的重要合作伙伴。
* 在教育领域，浙江大学基于火山引擎的 Hi Agent 平台和豆包大模型，仅用一周时间就落地了“浙大先生”智能体平台，广泛应用于 AI 科学家、课堂问答、教务咨询等多个场景，服务对象覆盖超过五万名在校师生。目前，C9 高校中已有六所与火山引擎达成合作，共同推进教育智能化发展。

展望未来，我们希望 AI 不再只是信息的感知、处理和生成工具，而是能够真正端到端地解决更复杂、更完整的问题，成为一个合格的智能体 Agent。

要实现这样的目标，我们必须在技术上做好三方面准备：

第一，是构建更强的模型，并具备多模态能力；
第二，是打造更先进的架构和工具，支持大模型在数字世界与物理世界中的实际操作，构建 OS 级的 Agent 能力；
第三，是通过 AI 云原生技术，持续降低模型的推理成本与延时，真正实现 AI 应用的“无障碍”。

我们相信，通过这些努力，豆包大模型不仅能够推动行业革新，也将引领我们走向一个更加智能、高效、便捷的未来。

== 豆包深度思考模型

豆包深度思考模型在专业领域的推理任务中表现非常出色。在数学推理方面，根据 MATH 2024 的评测，豆包深度思考模型的得分追平了 OpenAI 的 GPT-4 Mini（O3 Mini）；在编程竞赛 Codeforces 的评测中，其得分接近于 OpenAI 的 GPT-4（O1）。在科学推理任务 GPQA 中，模型的得分同样接近 O3 Mini，均达到或接近全球第一梯队的水平。

不仅如此，在创意写作等非推理任务中，模型也展现出了非常优秀的泛化能力，能够胜任更加广泛和复杂的应用场景。

豆包深度思考模型采用了 MoE（Mixture of Experts）架构，总参数量为 200B，但推理时激活的参数仅为 20B，因此在训练和推理成本上具有显著优势。也正是基于这样高效的算法设计，豆包深度思考模型不仅支持行业最高的并发处理能力，而且推理延迟仅有 20 毫秒，极具效率。

我们可以将深度思考模型应用于各种场景，比如解决复杂的逻辑难题、解读上市公司的财报、为高考志愿填报提供建议，甚至可以帮助解决高难度的数学和物理题。

对于一个优秀的思考模型来说，还需要具备“边想边搜”的能力。一个典型的应用场景是购物推荐：例如一对夫妻计划去露营，需要购买对应的装备。要做好这件事并不容易，因为需要考虑预算、孩子、天气，还要兼顾便携性和安全性。

豆包深度思考模型首先会拆解出整个决策过程中的关键注意事项，规划出需要获取的信息；接着通过三轮搜索获取完整的资料，最终给出全面周全的解决方案。

豆包深度思考模型还具备视觉推理能力，能够像人一样，不仅基于文字进行思考，还能基于所见画面进行深度理解。举几个例子：

第一个，根据照片猜测地理位置。模型依靠视觉理解能力，细致观察图片中的地貌、开发程度、地理特征等，进行深度分析，最终得出正确答案。

第二个，在国外点餐的场景中，豆包深度思考模型通过汇率换算来控制预算，同时周到地考虑老人与小孩的饮食偏好，还能细致避开过敏源相关菜肴，出色完成了整个任务。

在工作场景中，豆包深度思考模型可以看懂复杂的企业项目管理流程图，快速定位关键节点，并凭借强大的指令遵循能力，严格按照流程图内容回答客户问题。

基于更强的推理效果、更低的响应延迟和视觉理解能力，豆包 1.5 深度思考模型大大拓展了大模型的应用空间。

豆包大模型家族还带来了两个重要的模型更新：

首先，在文生图方面，豆包推出了 3.0 升级版本，进一步提升了文字排版质量，实现了实拍级图像生成效果，且可直接输出 2K 高清图像。在最新的文生图权威榜单中，豆包文生图 3.0 模型已超越众多业内主流模型，成功跻身全球第一梯队。

第二个升级是豆包的 1.5 视觉理解模型，主要包括两个关键更新：一是视觉定位更精准，二是对视频理解能力更智能。新模型支持多目标、小目标与通用目标的框定位和点定位，并可以基于定位实现计数、内容描述和 3D 定位等功能。

在视频理解方面，模型的能力也获得显著提升。基于更强更智能的视频理解能力，企业可以构建更加丰富有趣的应用场景。


== OS Agent

AI Agent 在实际应用中的两个主要方向：应用类 Agent 和 操作系统类 Agent（OS Agent）。

应用类 Agent，它们具备更强的专业性，专注于完成特定领域的任务，比如客服 Agent、数据 Agent、代码 Agent 等。这类 Agent 在垂直领域中拥有深入的知识和技能，能高效完成固定任务。

相比之下，OS Agent 具备跨场景的通用性和灵活性。它不仅可以操作浏览器、电脑、手机等设备，还可以与其他 Agent 协同合作，从而完成复杂任务。今年，Manus 等产品的出现点燃了市场对 OS Agent 的关注与热情。

在这个背景下，火山引擎打造了 OS Agent 的产品、工具和平台，向开发者和企业开放，帮助他们构建专属的 OS Agent。这正是火山引擎 OS Agent 解决方案的初心。

我们再来看两个复杂场景的应用：

1. Computer Use 场景：例如，我们希望 Agent 在电脑上调用剪映专业版，实现视频剪辑和配乐的功能；又或者，我们让 Agent 启动豆包 APP，生成图片和内容，并通过今日头条发布文章。这些都可以通过 Computer Sandbox 与豆包 1.5 的 UI Task 模型来实现。
2. Mobile Use 场景：比如希望 Agent 操作手机上的购票 APP，为用户完成高铁票的订购任务。在这一场景下，开发者可以基于云手机的 Mobile Sandbox，结合豆包的 UI Task 模型，完成整个订票流程。

今天，火山引擎正式发布了 GUI Agent 大模型——UI Task。这个模型整合了屏幕视觉理解、逻辑推理、界面元素定位与操作，使得 Agent 能以更接近人类的方式进行界面交互。与传统规则驱动的自动化工具相比，UI Task 模型拥有显著优势。

豆包的 UI Task 模型已在多个 OS 测试集中取得优异成绩，成为当前国内最领先的模型之一。它也已经正式上线方舟平台，面向外部开发者提供服务。同时，火山引擎的官网也将在接下来的两周内陆续上线 OS Agent 解决方案。

== 豆包 1.5 深度思考模型

豆包 1.5 深度思考模型现已正式发布。该模型在数学、编程、科学等多个专业领域表现出色，达到或接近全球第一梯队水平。它采用了 Mixture of Experts（MoE）架构，激活参数仅为 200 亿，配合高效推理算法，将延迟控制在 20 毫秒以内，实现低延迟高性能的响应体验。

接下来，我们通过几个实际应用场景，来看豆包 1.5 的强大能力：

1. 逻辑推理场景

面对一道复杂的逻辑题——在有限的信息中判断哪位妖怪在说真话，豆包 1.5 能准确提取关键信息，逐一假设与推理，并在过程中自我反思与校正，最终成功得出正确答案，展现出强大的逻辑推演与思辨能力。

2. 财报分析场景

输入一份长达 32 页的 2024 财年英文财报，要求分析不同区域的业绩差异及其与价格策略、产品结构和区域经济的关系。豆包 1.5 能精准理解任务，拆解分析问题，深度解析英文内容，并提取关键信息，给出准确且具有洞察力的分析结论。

3. 购物推荐场景

在豆包 APP 中，基于 1.5 模型进行了定向训练，使其具备“边思考、边搜索”的能力。以选购露营装备为例，用户提出了涉及低温、防雨、预算、便携性与安全性等多重复杂需求。模型能够清晰拆解用户需求，规划搜索路径，并通过多轮搜索，最终在预算范围内提供全面、贴心的推荐方案。

4. 视觉推理场景

豆包 1.5 拥有原生多模态能力，能够融合图像与文本信息进行推理。以分析一张航拍地貌图为例，模型能够识别湖泊的颜色、边缘盐结晶、周边旅游设施等关键视觉元素，结合地貌特征与地理背景，完成综合判断，精准定位目标地点。

5. 海外点餐决策场景

面对海外餐厅点餐这一实际需求，豆包 1.5 能够处理汇率换算、预算控制、家庭成员偏好及过敏原规避等多个因素。它可一步步做出最优选择，兼顾长辈与孩子口味、避开过敏食材，体现出强大的综合决策与个性化服务能力。

== 豆包视觉理解模型升级

包视觉理解模型全面升级，带来更精确的视觉定位与更智能的视频理解能力。

在视觉定位方面，新模型支持多种复杂场景，包括：

* *多目标定位*：可精准识别画面中的多个对象，确保识别全面性。
* *小目标定位*：即使在图像元素繁杂的情况下，也能准确识别细小目标。
* *通用目标识别*：适用于广泛类别的目标检测与定位。
* *点定位与计数*：能够精确标注多个物体位置，并快速完成数量统计。
* *3D 定位*：支持物体三维边界的空间感知与定位，增强模型对真实世界结构的理解。

在视频理解方面，模型实现了显著突破，具备：

* *实时指代记忆*：可在视频语境中准确理解“他”“它”等指代关系。
* *对话交互总结*：从人物对话中提炼关键信息，生成高质量摘要。
* *速度感知*：感知视频中动作的快慢变化，更贴近人类理解方式。
* *长视频处理*：支持对长时长视频的高效分析与结构化输出。

企业可基于豆包的视频理解能力，结合知识库和向量搜索技术，构建如安防监控、内容审核、智能搜索等多样化应用场景。
